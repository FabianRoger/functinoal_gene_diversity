---
title: "Analysis of nif_h data"
output:
  html_document:
    toc: true
    depth: 5
    theme: united 
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


```{r, "load.packages"}
library(dada2)
library(phyloseq)
library(tidyverse)
library(ggtree)
library(RColorBrewer)
library(knitr)
library(DECIPHER)
library(seqinr)
library(parallel)
library(Biostrings)
library(geiger)

#library(phytools)

#library(ShortRead)
#library(gridExtra)
library(ape)


```

### Files in directory
```{r}

path <- "~/Documents/01_PhD/01_Research/08_functional_gene_diversity/nifH_analysis/raw_data/"
fns <- list.files(path)

data.frame(forward = fns[grepl("R1", fns)],
           reverse = fns[grepl("R2", fns)]) %>% 
  kable(caption = "Files in directory")

```

### Quality profiles
```{r}
fastqs <- fns[grepl(".fastq$", fns)] # if non fastq files in directory
fastqs <- sort(fastqs) # sort to ensures forward/reverse reads are in same order

fnFs <- fastqs[grepl("_R1", fastqs)] # Just the forward read files
fnRs <- fastqs[grepl("_R2", fastqs)] # Just the reverse read files

# Get sample names from the first part of the forward read filenames
sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)

# Fully specify the path for the fnFs and fnRs
fnFs <- paste0(path, fnFs)
fnRs <- paste0(path, fnRs)


# plot quality profile of foward reads from first sample
plotQualityProfile(fnFs[[1]])+
  scale_y_continuous(limits = c(0,40))+
  scale_x_continuous(breaks = seq(0,300, 20))+
  geom_hline(yintercept = 30, colour = "grey", linetype = "dashed")+
  geom_hline(yintercept = 20, colour = "grey", linetype = "dashed")+
  labs(title = paste(sample.names[1], "foward", sep =" - "))

# plot quality profile of reverse reads from first sample
plotQualityProfile(fnRs[[1]])+
  scale_y_continuous(limits = c(0,40))+
  scale_x_continuous(breaks = seq(0,300, 20))+
  geom_hline(yintercept = 30, colour = "grey", linetype = "dashed")+
  geom_hline(yintercept = 20, colour = "grey", linetype = "dashed")+
  labs(title = paste(sample.names[1], "reverse", sep =" - "))


```


We can see the 5 random bases at the start of each sequence in the quality profiles. We will trim them in the next step. Besides, the quality profiles look as expected, with high quality in the forward and lower quality in the reverse read. 


### Trimming and paired-end merging of the Primers using fastx & PEAR

We sequenced the **nifH gene**, with the primers **IGK3** and **DVV**

```{r, echo = F}

data.frame(`.` = c( "sequence","direction", "matching position"),
           IGK3 = c( "GCIWTHTAYGGIAARGGIGGIATHGGIAA", "foward", "19-47"),
           DVV = c( "ATIGCRAAICCICCRCAIACIACRTC", "reverse", "388-413")) %>% 
  kable(caption = "primer sequences")

```

The expected fragment is 413 - 19 = 394bp long. 
Each read is 245 bp long (250bp - 5 random bp) this gives an expected overlap of 2*245bp - 394bp = 96bp
To ensure an overlap of at least 50bp, we cannot remove more than 46 bp in total.

We therefore set the pear merging parameter as follows:

+ maximal full length sequence `-m` 400 bp
+ minimal full length sequence `-n` 380 bp
+ minimum quality for two consecutive bases before trimming `-q` 20 (I set this rather low to ensure sufficient overlap. We will filter with expected error later anyway) 
+ minimum overlap after trimming `-v` 30

the `-j` flag specifies the number of cores in your computer

You will need the following programs to run the script below:

+ [fastx tools](http://hannonlab.cshl.edu/fastx_toolkit/)
+ [pear](http://sco.h-its.org/exelixis/web/software/pear/doc.html)
+ [vsearch](https://github.com/torognes/vsearch)


```{r, engine = "bash", eval=FALSE}

#here I am going to make two new directories to store
#output files for each step, as well as statistic files

mkdir nifH_analysis/pear_out nifH_analysis/fastq_filter_out

#change directory to the folder with all the -fastq files - I call it raw_fastq to denote that these are raw data files,
#but yours may have another name

cd nifH_analysis/raw_data

#The files names we get back from Microsynth have the following format; samplename_SXX_L001_RY_001.fastq,
#SXX denotes the well position, and RY is R1 (forward) or R2 (reverse). This means that we can list all
#the files in the directory, then extract the unique sample names to use to match up each pair of files 
#for a given sample. In this bash command, I get the filenames for all files in the directory that have
#a .fastq extension. I then 'pipe' a sed command that, for each file name, removes the chunk of text
#after the '_L001' in the name, leaving me with a list of sample names where each name is duplicated.
#I then pipe this list to a 'uniq' command that removes the duplicates, leaving me with a list of
#sample names that are stored in the FILES

FILES=$(ls *.fastq | sed 's/_L001_.*//g' | uniq)


#now we can loop through each sample to trim and merge each pair of files, followed by
#a filtering step using vsearch

for f in $FILES
do
	echo $f
	
	# trimm random bases

	/Applications/FASTX/fastx_trimmer -i $f'_L001_R1_001.fastq' -f 6 -o ../tmp_1.fastq -Q33
	/Applications/FASTX/fastx_trimmer -i $f'_L001_R2_001.fastq' -f 6 -o ../tmp_2.fastq -Q33
	
	#now I'm going to merge the sequences using pear - this matches and aligns the sequences
	#in each temp file, then give you statistics on how many reads have been merged, how many failed, 
	#and so on. You'll get four files as output; assembled, unassembled, 
	#unassembled.forward and unassembled.reverse, all of which are written to the pear_out directory. 
	
	pear -f ../tmp_1.fastq \
	     -r ../tmp_2.fastq \
	     -o '../pear_out/'$f \
	     -m 400 \
	     -n 380 \
	     -j 4 \
	     -q 20 \
	     -v 30

	#now I'm just deleting the temp files
	rm ../tmp_*

	#The next step is to further filter out low quality reads using usearch. This determines
	#the 'maximum expected error' for each sequence - see the usearch page for an explanation if this. 
	#(http://www.drive5.com/usearch/manual/exp_errs.html). I'm using a maximum error of 1; you may 
	#want to be more conservative (lower number), but keep in mind that you will lose more sequences, and 1 
	#is not that liberal regarding expected errors. The filtered files are then stored in the fastq_filter_out folder.

	/Applications/vsearch/bin/vsearch --threads 4 \
	         --fastq_filter '../pear_out/'$f'.assembled.fastq' \
	         --fastq_maxee 1 \
	         --fastq_maxns 0 \
	         --fastqout '../fastq_filter_out/'$f'.fastq' \
	         --eeout

	#Now, we need to rename all the sequences in each file to include the sample name 
	
	awk -v var=$f '/^@M01867/{sub("@","@"var"_"++i"_")}1' '../fastq_filter_out/'$f'.fastq' > '../fastq_filter_out/'$f'_lab.fastq'

	#just to save room, I'm now deleting the usearch output files and keeping only the relabeled files	
	rm '../fastq_filter_out/'$f'.fastq'
	
#closing the loop
done

#jumping back one directory
cd ..

#now I can concatenate all the final, labeled files into a single fastq file, which can then be converted to a fasta file for 
#the clustering steps using fastx tools
cat fastq_filter_out/*_lab.fastq > complete_set.fastq
```

convert fastq to fasta file
```{r, engine = "bash", eval = FALSE}
/Applications/FASTX/fastq_to_fasta -i nifH_analysis/complete_set.fastq -o nifH_analysis/complete_set.fasta -Q33
```

### summary statistics
```{r}

Raw_read_N <- c()

for (i in seq_along(fnFs)) {
  N <- system(paste("grep -c '^@M01867'", fnFs[i]), intern = T)
  Raw_read_N[i] <- as.numeric(N)
}

assembledReads <- list.files("nifH_analysis/pear_out/")
assembledReads <- sort(assembledReads[grep(".assembled.", assembledReads, fixed = TRUE)])
assembledReads <- paste0("~/Documents/01_PhD/01_Research/08_functional_gene_diversity/nifH_analysis/pear_out/", assembledReads)

assembled_Read_N <- c()

for (i in seq_along(assembledReads)) {
  N <- system(paste("grep -c '^@M01867'", assembledReads[i]), intern = T)
  assembled_Read_N[i] <- as.numeric(N)
}

hist((assembled_Read_N/Raw_read_N)*100, main = "% of assembled reads", xlab = "%")

```



```{r}
filteredReads <- sort(list.files("nifH_analysis/fastq_filter_out/"))
filteredReads <- paste0("~/Documents/01_PhD/01_Research/08_functional_gene_diversity/nifH_analysis/fastq_filter_out/", filteredReads)

filtered_Read_N <- c()

for (i in seq_along(filteredReads)) {
  N <- system(paste("grep -c '^@F'", filteredReads[i]), intern = T)
  filtered_Read_N[i] <- as.numeric(N)
}

hist((filtered_Read_N/assembled_Read_N)*100, main = "% of assambled reads that passed filter", xlab = "%")

hist((filtered_Read_N/Raw_read_N)*100, main = "% raw reads that got assembled AND passed filter", xlab = "%")

```

```{r}


comp.Length <- fasta.seqlengths("nifH_analysis/complete_set.fasta")

hist(comp.Length, main = "length histogram of complete_set.fasta")


```

## vsearch pipeline

### dereplication

+ removing global singletons

```{r, engine = "bash", eval = FALSE}

/Applications/vsearch/bin/vsearch --threads 4 \
		--derep_fulllength nifH_analysis/complete_set.fasta \
		--minuniquesize 2 \
		--sizeout \
		--output nifH_analysis/derep.fa


```

### OTU picking
+ 97% similarity
+ removing singleton OTUs

```{r, engine = "bash", eval=FALSE}
/Applications/vsearch/bin/vsearch --threads 2 \
    --cluster_size nifH_analysis/derep.fa \
    --centroids nifH_analysis/otus1_sorted.fa \
    --id 0.97 \
    --sizein \
    --sizeout \
    --relabel OTU_ \
    --minsize 2 \
    --maxaccepts 16 \
    --wordlength 8 \
    --strand both \
    --log nifH_analysis/cluster.log \
    --sizeorder  \
    --maxrejects 64

```

+ number of picked OTUs

```{r, engine="bash"}
grep -c '^>' nifH_analysis/otus1_sorted.fa
```


### Denovo chimera checking
```{r, engine="bash", eval = FALSE}
/Applications/vsearch/bin/vsearch --uchime_denovo nifH_analysis/otus1_sorted.fa \
    --chimeras nifH_analysis/otus1_chimeric_denovo.fa \
    --nonchimeras nifH_analysis/otus1_denonvo.fa \
    --uchimeout nifH_analysis/uchime_denovo.tab

```

### reference chimera checking

+ with nifh arb database as reference (all sequences)
    + File: nifH_2014April04.arb
    + Downloaded from [here](http://wwwzehr.pmc.ucsc.edu/nifH_Database_Public/)
    + opened in arb, exported all sequences in tree as fasta (nifH_dna.fasta) (unaligned)

```{r, eval = FALSE}

specLength <- fasta.seqlengths("nifH_analysis/nifH_dna.fasta")

specLength %>%
  as_data_frame() %>% 
  ggplot(., aes(x = value))+
  geom_histogram(binwidth = 100)+
  scale_x_continuous(breaks = seq(0,2500, 200))+
  labs(x = "length", title = "seqeuncing length distribution in reference db")

```

#### trimming of reference database

+ here I trim the reference database using our primers. Note that the primer sequences will be trimmed, too. 
+ also note that bbduk 'removes' the reads that match the primers. We keep and filter the 'removed' hits. 
+ finally, to keep more reads and because the database is composed of many short reads, I only require 1 primer to be found. 

```{r, engine = "bash", eval = FALSE}

/Applications/bbmap/bbduk2.sh in=nifH_analysis/nifH_dna.fasta \
      fliteral=ATIGCRAAICCICCRCAIACIACRTC,GCIWTHTAYGGIAARGGIGGIATHGGIAA \
			minkmerhits=1 \
			k=17 \
			copyundefined \
			rcomp=t \
			hammingdistance=1 \
			outm=nifH_analysis/nifH_dna_wP.fasta \
      overwrite=true \
			-Xmx6g

/Applications/bbmap/bbduk2.sh in=nifH_analysis/nifH_dna_wP.fasta \
			lliteral=GCIWTHTAYGGIAARGGIGGIATHGGIAA \
      rliteral=ATIGCRAAICCICCRCAIACIACRTC \
			k=17 \
			copyundefined \
			rcomp=t \
			hammingdistance=1 \
			out=nifH_analysis/nifH_dna_trimmed.fasta \
      overwrite=true \
			-Xmx6g
			
rm nifH_analysis/nifH_dna_wP.fasta
```

```{r, eval = FALSE}

specLength <- fasta.seqlengths("nifH_analysis/nifH_dna_trimmed.fasta")

specLength %>%
  as_data_frame() %>% 
  ggplot(., aes(x = value))+
  geom_histogram(binwidth = 3)+
  #scale_x_continuous(breaks = seq(250,450, 1), limits=c(315, 350))+
  labs(x = "length", title = "seqeuncing length distribution in reference db\ncut with primers")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

+ reference chimera checking

```{r, engine="bash", eval = FALSE}
/Applications/vsearch/bin/vsearch --uchime_ref nifH_analysis/otus1_sorted.fa \
    --db nifH_analysis/nifH_dna_trimmed.fasta \
    --chimeras nifH_analysis/otus1_chimera_ref.fa \
    --nonchimeras nifH_analysis/otus_nifh.fa \
    --uchimeout nifH_analysis/uchime_reference.tab


```

+ % of chimeric sequences
```{r}
NC <- system("grep -c '^>' nifH_analysis/otus1_chimera_ref.fa", intern = TRUE)
N <- system("grep -c '^>' nifH_analysis/otus_nifh.fa", intern = TRUE)
(as.numeric(NC) / as.numeric(N)) *100
```

+ % chimeric reads
```{r}
N <- 
  system(" grep '^>' nifH_analysis/otus_nifh.fa | perl -pe 's/^.+=(\\d+);/\\1/g'", intern = TRUE) %>% 
  as.numeric() %>% 
  sum()

NC <- 
  system(" grep '^>' nifH_analysis/otus1_chimera_ref.fa | perl -pe 's/^.+=(\\d+);/\\1/g'", intern = TRUE) %>% 
  as.numeric() %>% 
  sum()


(NC/N) * 100
```

In total, only very few reads are identified as chimeric. 


### checking for frameshifts

Here, we check the file of representative sequences `otus_nifh.fa` for frameshifts. For that we need an hmm profile that we build from the protein reference alignment. 

We build the hmmfile with [hmmbuild](http://hmmer.org) taking the nifh protein alignment from the arb database as input. 

+ with nifh arb database as reference (all sequences)
    + File: nifH_2014April04.arb
    + Downloaded from [here](http://wwwzehr.pmc.ucsc.edu/nifH_Database_Public/)
    + opened in arb, choose protein alignment (`ali_nifHprot`)
    + 41231

**the alignment has some sequences in it that are not valid protein sequences**

We read it into R and check for invalid sequences by grepping for sequences that do not match valid AA characters:
```{r, eval = FALSE}

paste(c("^[", paste(AA_ALPHABET[1:26], collapse = ","),"]$"), collapse  = "")

nifh_AA <- readAAStringSet("nifH_analysis/nifH_prot_aligned.fasta")

Valid_seq <- grepl( paste(c("^[", paste(AA_ALPHABET[1:26], collapse = ","),",\\.,-]+$"), collapse  = ""), nifh_AA, ignore.case = TRUE)

#number of invalid AA seqeunces
length(nifh_AA) - sum(Valid_seq)

#excluding invalid sequences
nifh_AA_valid <- nifh_AA[Valid_seq]

writeXStringSet(nifh_AA_valid, file="nifH_analysis/nifH_prot_aligned.fasta", format="fasta")

```

+ with the clean protein alignment we now build our hmmprofile

```{r, engine = "bash", eval = F}
/Applications/hmmer/binaries/hmmbuild nifH_analysis/nifh_hmm nifH_analysis/nifH_prot_aligned.fasta

```

+ With that profile we check for frameshift errors in the representative sequences 

Files: 

+ `otus_nifh.fa`
+ `nifH_hmm`

this script does: 

+ cleaning coding sequences using hmmframe
+ output - removes insertions, denoted by 'i' from hmmframe output

```{r, eval = FALSE}

#function for editing out 'i' in sequences
seq.clean<-function(seq) {

	attrs<-attributes(seq)
	seq<-seq[grep('i',seq,invert=TRUE)]
	attributes(seq)<-attrs
	return(seq)
}

trans.count<-function(seqs) {

	if(length(grep('[\\*X]',translate(seqs))) > 0) {
		return(grep('[\\*X]',translate(seqs)))
	}else {
		return(0)
	}
}

#give fasta input file 
input.file<-'nifH_analysis/otus_nifh.fa'

#list HMM file
hmm.file<-'nifH_analysis/nifH_hmm'

#full path to hmmframe (as $PATH is ignored if called from GUI)
hmmframe <- c("/Applications/HMM-FRAME/hmmframe")

#set number of cores to use - best to set to number of cores #actually in the computer.
n.core<-3

#################################################
#HMMFRAME processing
#################################################
#splitting file into multiple parts to run HMMFRAME on different cores

seqs<-read.fasta(input.file,forceDNAtolower=FALSE,strip.desc=TRUE)

z<-rep(1:n.core,length.out=length(seqs))
test<-split(seqs,z)

#temp directory for split files
system(paste('mkdir ',getwd(),'/nifH_analysis/TMP_hmmframeR',sep=''))


for(i in 1:length(test)) {

	write.fasta(test[[i]], names=lapply(test[[i]],function(x) {attr(x,'Annot')}),
				file.out=paste(getwd(),'/nifH_analysis/TMP_hmmframeR/hmmin_',i,'.fa',sep=''),nbchar=1000)

}

#starts n.core HMMFRAME for each split file in TMP_hmmframeR directory.
mclapply(list.files(paste(getwd(),'/nifH_analysis/TMP_hmmframeR/',sep='')),
         function(x) {system(paste(hmmframe, hmm.file,' ',
                                   paste(getwd(),'/nifH_analysis/TMP_hmmframeR/',x,sep=''),' ',
                                   paste(getwd(),'/nifH_analysis/TMP_hmmframeR/OUT_',x,sep=''),
                                   ' 0'))},mc.cores=n.core)

#concatenate split HMMFRAME output files to temp file
system(paste('cat ',getwd(),'/nifH_analysis/TMP_hmmframeR/OUT* > ',getwd(),'/nifH_analysis/Temp.fa',sep=''))

```

```{r}
#function for counting the number of frameshifts in output
Attr_to_DF <- function(x) {
  
  L <- strsplit(x, " ")[[1]]
  Values <- c(L[1], lapply(L[-1], function(x) strsplit(x,"=")[[1]][2] ))
  names(Values) <- c("seq.nam", lapply(L[-1], function(x) strsplit(x,"=")[[1]][1] ))
  return(Values)
  
}

#read in concatenated sequence file
seqs.hmmout <- read.fasta(paste(getwd(),'/nifH_analysis/Temp.fa',sep=''),forceDNAtolower=FALSE,strip.desc=TRUE)

Attr_list <- lapply( lapply(seqs.hmmout, function(x) attr(x, "Annot")), Attr_to_DF)
Attr_DF_err <- bind_rows(lapply(Attr_list, data.frame, stringsAsFactors=FALSE)) %>% 
filter(., error_num > 0) %>% 
  select(1:7, -hmm_name) 

nrow(Attr_DF_err)

gsub(".+size=(\\d+);", "\\1", Attr_DF_err$seq.nam) %>% as.numeric %>% hist(main = "size of OTUs with FS errors",
                                                                           xlab= "OTU size")

seqs.noFS <- seqs.hmmout[! names(seqs.hmmout) %in% Attr_DF_err$seq.nam]
```


There are only few reads with frameshifts and those reads are from OTUs that have only few sequences in it. 
However we only check OTU representative sequences and we don't want OTU rep's that originated from frameshift errors. 
We exclude those sequences

```{r}

lengths <- unlist(lapply(seqs.hmmout,getLength))

seqL <- lengths %>% 
  data.frame(length = .) %>% 
  rownames_to_column(var = "names")
  
ggplot(seqL, aes(x = length))+
  geom_histogram(binwidth = 1)

ggplot(seqL, aes(x = length))+
  geom_histogram(binwidth = 1)+
  scale_x_continuous(limits=quantile(seqL$length, c(0.005, 0.995)) + c(-1,1),
                     breaks = seq(0,600,3))+
  labs(title = '0.05% - 99.5% quantile of sequence length\'s')
```

The vast majority of the sequences comes in 3 length: 387, 390 & 393 nucleotides. This is in good agreement with the expected length. 

We keep all sequences >= 384 nt & <= 396 nt. 

```{r, eval=FALSE}
Seq_exclude <-  seqL[seqL$length < 384 | seqL$length > 396,]$names 
seq_clean <- seqs.noFS[! names(seqs.noFS) %in% Seq_exclude]

#writes sequences that do not have frameshifts to fasta file
write.fasta(seq_clean,names=names(seq_clean),
            file.out= "nifH_analysis/otus_nifh_fsc.fa",
            open='w',nbchar=1000)


```

dropping singletons

```{r, engine="bash", eval = FALSE}

/Applications/vsearch/bin/vsearch --sortbysize nifH_analysis/otus_nifh_fsc.fa \
    --sizein \
    --minsize 2 \
    --output nifH_analysis/otus_final_nosingle.fa \
    --sizeout 

```


### mapping reads to OTUs

We now map the original paired reads to the representative sequences

+ mapping reads

```{r, engine = "bash", eval = FALSE}
/Applications/vsearch/bin/vsearch --usearch_global nifH_analysis/complete_set.fasta \
    --db nifH_analysis/otus_final_nosingle.fa \
    --id 0.97 \
    --self \
    --maxaccepts 16 \
    --wordlength 8 \
    --strand both \
    --log cluster.log \
    --maxrejects 64 \
    --uc nifH_analysis/otu_table_nifh.uc
```

+ converting uc file into OTU table , removing size annotation from OTU names & and saving it as tab delimited text file

```{r}
OTU_nif <- import_usearch_uc('nifH_analysis/otu_table_nifh.uc')

colnames(OTU_nif) <- gsub("(OTU_\\d+);.+", "\\1", colnames(OTU_nif))

write.table(OTU_nif, "OTU_nifh.txt", sep = "\t")

dim(OTU_nif)

```


+ percentage of reads mapped to OTU's

```{r}
merged_reads <- system("grep -c '^>' nifH_analysis/complete_set.fasta", intern = TRUE)

sum(OTU_nif) / as.numeric(merged_reads) * 100
````



## filtering of nifh paralogues

#### importing & selecting seqeunces from UniProt

There are 4 genes that are known nifH paralogues that are picked up by the primers used in this study but also know not to be implicated in nitrogen fixation. We retrieve representative sequences for these paralogues from [UniProt](http://www.uniprot.org) (accessed on 2016-10-20) with the following search term: 

**gene:bchx OR gene:bchl OR gene:frxc OR gene:nflh**

The search finds a total of 470 sequences. We download the protein sequences as fasta 

```{r}
UniProt <- read_tsv("nifH_analysis/uniprot_nifh_paralogues.tab")

UniProt <- UniProt %>% 
  mutate(Gen.name = ifelse(grepl("bchx", `Gene names`, ignore.case = T),"bchx",
                           ifelse(grepl("bchl", `Gene names`, ignore.case = T),"bchl",
                                  ifelse(grepl("frxc", `Gene names`, ignore.case = T),"frxc",
                                         ifelse(grepl("nflh", `Gene names`, ignore.case = T),"nflh", NA)))))

ggplot(UniProt, aes(x = Gen.name))+
  geom_bar(stat="count")
```

There are only few representative sequences from **nflh** and **frxc**, wherefore I keep them all. 
**bchx** and especially **bchl** have more sequences and we can apply some filters.

```{r}
Uncultured <- UniProt %>% filter(Gen.name %in% c("bchx","bchl")) %>%
  filter(., grepl("environmental|uncultured" , .$`Taxonomic lineage (ALL)`, perl = T, ignore.case = T)) 

ggplot(Uncultured, aes(x = Gen.name))+
  geom_bar(stat="count")
```

+ excluding sequences from the uncultured bacteria leaves us with sufficient representative sequences. We keep the remaining sequences. 

```{r}
anti_join(UniProt, Uncultured) %>%
ggplot(., aes(x = Gen.name))+
  geom_bar(stat="count")
  
```

+ filtering sequences

```{r}
Uniprot_AA <- readAAStringSet("nifH_analysis/uniprot_nifh_paralogues.fasta")

#rename sequences to just keep the Entry
names(Uniprot_AA) <- 
  gsub(".+\\|([\\w\\d]+)\\|.+", "\\1", names(Uniprot_AA), perl = T)

#filter sequences
Uniprot_AA <- Uniprot_AA[! (names(Uniprot_AA) %in% Uncultured$Entry)]

#align sequences
UniAA <- AlignSeqs(Uniprot_AA, verbose = FALSE)

#mask sequences
masked_Uni <- maskGaps(AAMultipleAlignment(UniAA), min.fraction = 0.95, min.block.width = 1) %>% as(., "AAStringSet")

# check for outliers
Dist <- DistanceMatrix(masked_Uni, verbose = FALSE)

Dist_seq <- sort(colSums(Dist), decreasing = T)

plot(Dist_seq, ylab = "colSums(Dist)", 
     main = "Sum of Distances for all Sequences", 
     xlab = "Sequences, decreasing order of total distance") 

UniProt[UniProt$Entry %in% names(which(Dist_seq > 250)),] %>% select(Entry, `Taxonomic lineage (ALL)`, `Gen.name`) %>% kable


#exclude those sequences from reference sequences
Uniprot_AA <- Uniprot_AA[!names(Uniprot_AA) %in% names(Dist_seq)[1:10]]

```



## Alignment and Tree building

To build a phylogenetic tree of the centroid OTU sequences, we align them together with the representative sequences from the nifh ARB database. 

in ARB
+ we select the `tree_RepSeq_nifHPCRregion_AA_April2014_CDHITAA` tree. It's the most comprehensive tree in the database (6212 sequences). 
+ we export the sequences in the tree as unaligned nucleotide fasta file (`ref_dna.fasta`)
+ we merge the OTU file to the file with reference sequences

```{r, engine='bash', eval = FALSE}

cat nifH_analysis/otus_final_nosingle.fa nifH_analysis/ref_dna.fasta > nifH_analysis/nifH_all_dna.fasta

grep -c '^>' nifH_analysis/nifH_all_dna.fasta

```


+ we use a custom script to align the reverse translation of the nucleotide file 

> Script for aligning nucleotide sequences using a seed amino acid alignment and HMMER. Besides the output nucleotide alignment FASTA file, this script spits out a FASTA format file with the aligned amino acids, prot_aligned.fasta, as well as two error log files that show which sequences were removed due to no matching domains at the set e-value threshold.

+ the script needs a reference protein alignment as input. We use the same one that we prepared for the frameshift analysis earlier (cleaned protein alignment containing all sequences in the arb database)


**here I use the script only to orientate the reading frame of the DNA seqeunces, corretc remaining Frameshifts and translate them into AA**

### aligning

**the scrip can't be called from within Rmarkdown - I run it in the shell with the command below**

```{r, engine = "bash", eval = FALSE}

python hmmalign_nucmap.py -f nifH_all_dna.fasta \
                          -s nifH_prot_aligned.fasta \
                          -o nifh_all_dna_aligned.fasta \
                          -e 0.00001  
                 
```

+ both error files are empty which means that no sequences were removed

```{r, engine = 'bash'}
ls -lh nifH_analysis/error*
```

### degapping alignemnt, adding paralogue references (AA) & re-aligning

+ degapping 
+ joining paralogue references

```{r, eval = FALSE}

seqs <- readAAStringSet("nifH_analysis/prot_aligned.fasta")
seqs <- AAStringSet( toupper( gsub("-", "", seqs)))
seqs <- c(seqs, Uniprot_AA)

writeXStringSet(seqs, "nifH_analysis/nifh_all_prot_wP.fasta")

```

+ press hmmfile

```{r, engine = "bash", eval = FALSE}

/Applications/hmmer/binaries/hmmpress nifH_analysis/nifh_hmm

```

+ realign

**here I produce the actual alignment that I also take for the tree building**

```{r, engine = 'bash', eval = FALSE}
/Applications/hmmer/binaries/hmmalign -o nifH_analysis/nifh_all_prot_wP_aligned.Sto \
                                         nifH_analysis/nifh_hmm \
                                         nifH_analysis/nifh_all_prot_wP.fasta

```

```{python, engine.path='/usr/local/opt/python/bin/python2.7', eval = FALSE}
from Bio import AlignIO

ali_in = AlignIO.read(open("nifH_analysis/nifh_all_prot_wP_aligned.Sto"), "stockholm")
out_handle = open("nifH_analysis/nifh_all_prot_wP_aligned.fasta","w")
AlignIO.write(ali_in, out_handle, 'fasta')
out_handle.close()
```


```{r, eval = FALSE}
seqs_align <- readAAStringSet("nifH_analysis/nifh_all_prot_wP_aligned.fasta")

```


### masking alignment

mask alignment by

+ masking columns with > 95% gaps 

```{r, eval = FALSE}

# rename seqeunces
## strip size annotation after OTU name
## strip <unknown description> from reference seqeunce names

names(seqs_align) <- gsub('(OTU_\\d+);.+', '\\1', names(seqs_align))
names(seqs_align) <- gsub('\\s<unknown description>', '', names(seqs_align))


# mask all columns with > 95% gaps characters across all sequences
masked <- maskGaps(AAMultipleAlignment(seqs_align), min.fraction = 0.95, min.block.width = 1)

# backtransform to AAStringset and write the alignment as fasta
seq_masked <- as(masked, "AAStringSet")

writeXStringSet(seq_masked, file= "nifh_all_prot_aligned_masked.fasta")
```

### construct tree

```{r, engine = "bash", eval = FALSE}
/Applications/FastTree/FastTree nifh_all_prot_aligned_masked.fasta > FastTree_wParalogues.tre
```


## Tree plotting and filtering

###  phylogenetic tree highlighting disitribution of OTUs and reference sequences

branches that lead to OTU's are in blue, branches that lead to reference sequences are in yellow

```{r, fig.height= 30, fig.width=8}

TREE <- read.tree("FastTree_wParalogues.tre")


# using nifhl protein sequences as outgroup
TREE <- root(TREE, outgroup = UniProt[UniProt$Gen.name == "nflh",]$Entry)

TREE <- root(TREE, node = MRCA(TREE, c("UncB4806", "PaeDur18")))

TREE_plot <- groupOTU(TREE, TREE$tip.label[grep('OTU', TREE$tip.label )], group_name = "group") 

ggtree(TREE_plot, aes(color=group))+
  scale_color_manual(values = c("orange", "darkblue"))

```


### assiging of metadata for the reference sequences

+ We exported the metadata for the sequences that we also used for building the tree from ARB

```{r}
Ref_meta <- read_tsv("nifH_analysis/ref_spec_meta.txt", 
                     col_names = c("names",
                                   "Raymond_group",
                                   "Young_group",
                                   "full_name",
                                   "AMINO_2014",
                                   "DNA_2003",
                                   "isolation_source",
                                   "nuc_length",
                                   "PutativeChimera"))


kable(head(Ref_meta))

```

from the [ARB_nif_documentation](http://wwwzehr.pmc.ucsc.edu/nifH_Database_Public/) we can read that:

> Raymond_group- Major cluster designation  (1-5) as defined by Raymond et al. Clusters 1-3 annotated.
> Young_group- Major cluster designations (B, A, C) as used by Young.
> AMINO_2010 (**here** AMINO_2014) - Current designation of clusters using the Alphabetical clustering system of Zehr
et al. 2003. 
> PuatativeChimera – Sequences identified as possible chimeras using UCHIME.


### Tree highlighting nifh cluster accoring to Zehr et al 

+ red circles around nodes signify bootstrap support > 0.9

```{r, fig.height= 6, fig.width=6}

Ref_meta <- mutate(Ref_meta, Zehr_group = gsub("(\\d).+", "\\1", AMINO_2014))

ggplot(Ref_meta, aes(x = Raymond_group, y = Young_group))+
  geom_bin2d()

ggplot(Ref_meta, aes(y = Zehr_group, x = Young_group))+
  geom_bin2d()
```


```{r, fig.height= 30, fig.width=8}
rownames(Ref_meta) <- Ref_meta$names

p <- ggtree(TREE)

pR <- p %<+% Ref_meta

pR + 
  geom_tippoint(aes(color=Zehr_group), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(5,"Set1")))+
  geom_hilight(node = MRCA(TREE, c("P0CY53", "UniNi110")))

```
According to the brought characterization of the Young group


**Heller et al. 2014**

> **Cluster I** nifH primarily comprises ‘conventional’ nifH, which encodes the Fe protein of Mo nitrogenase (Igarashi, 2003), as well as vnfH genes that encode the Fe protein of V nitrogenase. [...] Organisms that contain Cluster 1 nifH genes include cyanobacteria and alpha-, beta- and gamma-proteobacteria.

> **Cluster II** nifH genes encode the Fe protein of ‘alternative’ nitrogenases that contain iron but do not contain Mo or V 

> **Cluster III** is dominated by genes encoding Fe proteins of nitrogenases primarily of anaerobes, including meth- anogens and sulfate reducers; these nitrogenases likely contain Mo.

> **Clusters IV and V** (sometimes grouped as Cluster IV) contain nifH paralogues whose functions include photopigment biosynthesis (Young, 2005) and non-N2-fixation electron transport (Raymond et al., 2004). It has also been suggested that the function of Cluster IV nifH paralogues found in non-N2-fixing Archaea is the biosynthesis of cofactor F430, essential to the production of methane 


As summarized by **Gaby and Buckley 2012** 


> Phylogenetic analyses of nifH gene sequences have revealed five primary clusters of genes homologous to nifH [12–15]. **Cluster I** consists of aerobic nitrogen fixers including Proteobacteria, Cyanobacteria, Frankia, and Paenibacillus. **Cluster II** is generally thought of as the alternative nitrogenase cluster because it contains sequences from FeFe and FeV nitrogenases which differ from the conventional FeMo cofactor-containing nitrogenase. **Cluster III** consists of anaerobic nitrogen fixers from Bacteria and Archaea including for instance the Desulfovibrionaceae, Clostridia, Spirochataes, and Methanobacteria. **Cluster IV and cluster V** contain sequences that are paralogs of nifH and which are not involved in nitrogen fixation


>  In addition, many of these primers will amplify genes that do not mediate nitrogen fixation, and thus it would be advisable for researchers to screen their sequencing results for the presence of non-target genes before analysis. 



```{r}
Parallogues_G4 <- tips(TREE, MRCA(TREE, c("P0CY53", "UniNi110")))
```

+ % of reads to be excluded

```{r}
OTU_nif[, colnames(OTU_nif) %in% Parallogues_G4] %>% sum / sum(OTU_nif) * 100
```

+ % of OTUs to be excluded 

```{r}
sum(colnames(OTU_nif) %in% Parallogues_G4) / ncol(OTU_nif) * 100
```


### Tree highlighting cluster of known nifh parallogues

```{r, fig.height= 30, fig.width=8}
rownames(UniProt) <- UniProt$Entry

p <- ggtree(TREE)

pR <- p %<+% UniProt 

pR + 
  geom_tippoint(aes(color=Gen.name), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(4,"Set1"))) +
  geom_hilight(node = MRCA(TREE, c("O30837", "B3QZE1")))

```


```{r}
Parallogues <- tips(TREE, MRCA(TREE, c("O30837", "B3QZE1")))
```

+ % of reads to be excluded

```{r}
OTU_nif[, colnames(OTU_nif) %in% Parallogues] %>% sum / sum(OTU_nif) * 100
```

+ % of OTUs to be excluded 

```{r}
sum(colnames(OTU_nif) %in% Parallogues) / ncol(OTU_nif) * 100
```


** I exclude all sequences belonging to the Cluster IV / V as defined by Zehr et al and as highlighted in the tree above this tree (and listed in `Parallogues_G4`)**


### Filtering of OTU table

+ calculate and save the % of Cluster IV Sequences in each sample

```{r}

Frct_Par <- rowSums(OTU_nif[ ,colnames(OTU_nif) %in% Parallogues_G4]) / rowSums(OTU_nif) %>% 
  data.frame( frct.par = .)

Frct_Par <- Frct_Par %>% rownames_to_column(., var = "sample") %>% 
  mutate(sample = sub("F", "", sample))

ggplot(Frct_Par, aes(x = frct.par))+
  geom_histogram()+
  scale_x_continuous(limits = c(0,1), breaks = seq(0,1,0.1))

write.table(Frct_Par, "Fraction_Parallogues_nifh.txt", sep = "\t")
```

+ remove OTUs from OTU table

```{r}
OTU_nifh_nC4 <- OTU_nif[ ,! colnames(OTU_nif) %in% Parallogues_G4]

dim(OTU_nifh_nC4)

write.table(OTU_nifh_nC4, "OTU_nifh_clean.txt", sep="\t")
```

+ remove all Cluster IV Sequences from Tree (keep one as outgroup)

```{r}
TREE_nC4 <- drop.tip(TREE, Parallogues_G4[-which(Parallogues_G4 == "P0CY53")])

TREE_nC4 <- root(TREE_nC4, outgroup = "P0CY53", resolve.root = TRUE)
```

```{r, fig.height= 20, fig.width=10}
p <- ggtree(TREE_nC4)

pR <- p %<+% Ref_meta

pR + 
  geom_tippoint(aes(color=Zehr_group), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(5,"Set1"))) 
  #geom_nodepoint(colour = ifelse(TREE_nC4$node.label >= 0.9, "red", NA), size = 0.1)
  #geom_hilight(node = MRCA(TREE, c("P0CY53", "UniNi110")))

```


```{r}
# calculating distance matrix between all tips
CP <- cophenetic.phylo(TREE_nC4)

# subset distance matrix for only OTUs in rows and only reference Sequences in columns
CP_OTU <- CP[grepl('OTU_', names(CP[1,])), ! grepl('OTU_', names(CP[1,]))]

#define function to look up median reference sequence (weighed by distance)

closest.hit <- function(x, N) {
  
  #get 10 closest reference tips an corresponding groups
  z <- sort(x)[1 : N] 
  Groups <- Ref_meta[match(names(z), Ref_meta$names), ]$Zehr_group
  
  #exclude unclassified reference tips
  z <- z[!is.na(Groups)]
  Groups <- Groups[!is.na(Groups)]
  
  # if all classified reference tips are from the same group, assign this group
  if ( length(unique( Groups)) == 1) {
    OTU_group <- Groups[1] 
  
    #if the weight of the closet non-NA tip is larger then the sum of the remaining non-NA groups assign this group  
    } else if ((1/z[1]) > sum( 1/ z[2: length(z)])) {
  
      OTU_group <- Groups[1]
    
      # otherwise assign most frequent group, weighted by 1 / distance from tip
      } else {
    Groups <- rep(Groups, each = 1/z)
    OTU_group <- names( sort( table( Groups), decreasing = T)[1])
  }
                    
return(OTU_group)
}
  
  
OTU_group <- data.frame(OTU = rownames(CP_OTU),
                        Zehr_group = apply(CP_OTU, 1, closest.hit, N=10), 
                        stringsAsFactors = FALSE)

write.table(OTU_group, "OTU_nifh_Zehr.txt", sep = "\t")

OTU_group %>% 
  ggplot(aes(x = Zehr_group))+
  geom_bar(stat = "count")
```

```{r, fig.height= 25, fig.width=10}
p <- ggtree(TREE_nC4)

pR <- p %<+% OTU_group

pR + 
  geom_tippoint(aes(color=Zehr_group), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(3,"Set1")[c(1,3)])) 


```
### trimm all non_OTU seqeunces from the TREE


```{r}

non_OTU <- TREE_nC4$tip.label[! grepl('OTU', TREE_nC4$tip.label)]
non_OTU <- non_OTU[! non_OTU == "P0CY53"] 

TREE_OTU <- drop.tip(TREE_nC4, non_OTU)

TREE_OTU <- root(TREE_OTU, outgroup = "P0CY53")

TREE_OTU$root.edge <- 0

write.tree(TREE_OTU, "TREE_nifh_OTUonly.tre")
```

```{r, fig.height= 25, fig.width=10}
p <- ggtree(TREE_OTU)

pR <- p %<+% OTU_group

pR + 
  geom_tippoint(aes(color=Zehr_group), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(3,"Set1")[c(1,3)])) 

```

### make tree ultrametric

Because the downstream estimation of phylogenetic diversity requires an ultrametric tree, we use [PATHd8](http://www2.math.su.se/PATHd8/) for the phylogenetic dating. 

> The method is based on estimating node ages by mean path lengths from the node to the leaves

It is not the most fanciful method but I think it will be sufficient for the purpose to get an ultrametric tree for the estimation of phylogenetic diversity. Also it calculates almost instantaneously and more advanced methods (such as BEAST) will take a long time to run with such large trees. 

note that PATH8 produces a big file with lots of additional information that is not very relevant in our case. Therefore we grep the tree from the produced output file and save it separately. 

```{r, engine = "bash", eval=FALSE}
/Applications/PATHd8/PATHd8 TREE_nifh_OTUonly.tre TREE_nifh_um.tre

grep '^d8 tree' TREE_nifh_um.tre > TREE_nifh_um_oT.tre

```


```{r}
TREE_um <- read.tree("TREE_nifh_um_oT.tre")
```

```{r, fig.height= 20, fig.width=10}
p <- ggtree(TREE_um)

pR <- p %<+% OTU_group

pR + 
  geom_tippoint(aes(color=Zehr_group), size = 1) + 
  theme(legend.position="right") +
  scale_colour_manual(values = c(brewer.pal(3,"Set1")[c(1,3)])) 

```

### removing cleaned OTUs from alignment and complete seqeunce file

+ save list of removed OTUs

```{r, eval = FALSE}
OTU_excl <- Parallogues_G4[grepl('OTU_', Parallogues_G4)]

write(OTU_excl, "excluded_OTUs.txt")
```


+ keep only confirmed nifh seqeunces in the alignment

```{r, eval = FALSE}

# filter out OTUs that are to be excluded as well as sequences from UniProt / teh ARB reference database
seq_OTU <- seq_masked[grepl('OTU_', names(seq_masked)) & ! names(seq_masked) %in% Parallogues_G4]

# remove all-gap columns
seq_OTU <- maskGaps(AAMultipleAlignment(seq_OTU), min.fraction = 1, min.block.width = 1)

# backtransform to AAStringset
seq_OTU <- AAStringSet(toupper( as(seq_OTU, "AAStringSet")))

# write the alignment as fasta
writeXStringSet(seq_OTU, "onlyOTU_prot_align.fasta")

```

+ filter out reads from excluded OTUs from complete_set.fasta 

```{r, eval = FALSE}
# read in usearch mapping file
UC <- read_tsv("nifH_analysis/otu_table_nifh.uc", col_names = FALSE)

# make column with OTU names (stripped from size annotation)
UC <- mutate(UC, OTU = gsub("(OTU_\\d+);.+", "\\1", X10))

# get list of reads names that do not belong to OTUs that should be excluded
Reads_to_keep <- UC[!UC$OTU %in% OTU_excl, ]$X9

# read in the complete set of merged reads
Complete_set <- readDNAStringSet('nifH_analysis/complete_set.fasta')

# strip expected error annotation from read names
names(Complete_set) <- gsub("(.+)\\s.+", "\\1", names(Complete_set))

# filter for reads in 'Reads_to_keep'
Filtered_set <- Complete_set[names(Complete_set) %in% Reads_to_keep]

# write fasta file with filtered sequences
writeXStringSet(Filtered_set, "complete_set_filtered.fasta")
```
